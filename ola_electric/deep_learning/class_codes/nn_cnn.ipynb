{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09aea26a-63be-4ab0-ba0b-8a90dbcab407",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path_mnist_train = \"/Users/gunnvantsaini/OneDrive/project_codes/content/dl_basics/vision/sony/data/mnist_train.csv\"\n",
    "local_path_mnist_test = \"/Users/gunnvantsaini/OneDrive/project_codes/content/dl_basics/vision/sony/data/mnist_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9457ec6e-b910-46dd-8be6-ae20335ce51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6466ce3-b607-4f16-8647-dd9e7c408a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv(local_path_mnist_train)\n",
    "mnist_test = pd.read_csv(local_path_mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2005ba-f596-49b8-b884-fd75fd6b3da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849884c-a645-4b2d-8323-7647c56747b8",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "- Some way of batching the data\n",
    "- Some abstraction around model\n",
    "- Some abstraction around weight updates\n",
    "- Some abstraction around loss functions\n",
    "- Logging when I am training (print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f6ac0-60e6-4b4a-b750-a3789fa66e01",
   "metadata": {},
   "source": [
    "### Batched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b8c8b6-99a6-40a2-87b8-7971f6046e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12cf2c9-c1bf-4296-b08c-a443cd93c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return {'X':x,'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be85f7e9-cb77-4701-ba70-931fdcebd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Students():\n",
    "    def __init__(self):\n",
    "        self.names = []\n",
    "    def add(self,name):\n",
    "        self.names.append(name)\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.names[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bead8f3-2f46-4b87-a582-ad489c098525",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Students()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af3c9f03-994a-4aaf-bddc-387a449a5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.add('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34dc89c6-2694-434f-b5d0-52908dae1cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a68dfc38-5f79-447e-9799-adb2e03665e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd2ad5eb-6ba4-456f-8b31-02172c6c270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist_train.drop('label',axis=1).values\n",
    "y = mnist_train['label'].values\n",
    "d_train = Mnist(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63d721c7-4124-4c59-8b12-441dede0fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = DataLoader(d_train,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1930cbe6-8521-449d-af50-67756ffd97c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'y': tensor([1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3, 1, 2, 0, 7, 5, 8, 6, 2, 0,\n",
       "         2, 3, 6, 9, 9, 7, 8, 9])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(d_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb94c5-ca52-4132-830a-6f92be67279a",
   "metadata": {},
   "source": [
    "### Model Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b58d2fd-5a12-4fac-b5b4-bf72a2cc5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68d210f8-bc6f-4a06-9941-c99735ef187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784,3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(3,10)\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        x = self.layer1(X)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b96dc5-7271-4103-a85e-6d5f05d26246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(784,3),nn.ReLU(),nn.Linear(3,10),nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self,X):\n",
    "        x = self.classifier(X)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e499aaa-0c44-468c-bab6-fc259437b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()\n",
    "m1 = Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "688d41b8-36ee-4a28-a096-6c3f83a1dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn((1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7876af0e-ff33-4fe0-88b1-33a2bcc81c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/01sjg2sx6tl3y72r2klm24c80000gn/T/ipykernel_24070/2995878503.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0966, 0.0657, 0.1099, 0.1501, 0.1297, 0.0999, 0.0583, 0.0665, 0.1027,\n",
       "         0.1205]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "623b0fa7-a91f-42a8-bd3f-0842a4a69515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniforge3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0923, 0.1326, 0.0623, 0.1120, 0.1450, 0.1400, 0.0553, 0.0922, 0.1113,\n",
       "         0.0571]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c317bc2-9ff3-4a55-8229-6bcb0d89b274",
   "metadata": {},
   "source": [
    "### Abstraction around weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "582e94ce-20da-421d-a326-7e6a01c304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c7c7c21-4549-4774-8a1f-26073f25c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = opt.SGD(m.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c66d0b-b99b-4dff-bb1d-37054c6f4540",
   "metadata": {},
   "source": [
    "### Abstraction around loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4f19cd9-2099-4dbc-b7f9-175c331d86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0934ebe-03b1-480e-b0df-9dddd202d2ae",
   "metadata": {},
   "source": [
    "### Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4704e7aa-0522-4999-b82b-11fd695aa1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/01sjg2sx6tl3y72r2klm24c80000gn/T/ipykernel_24070/2995878503.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:2.192112795738947, acc:0.2609761904761905, epoch:0\n",
      "Loss:2.0375873780931744, acc:0.44895238095238094, epoch:1\n",
      "Loss:1.9459630636260623, acc:0.6071666666666666, epoch:2\n",
      "Loss:1.848797149135953, acc:0.6755952380952381, epoch:3\n",
      "Loss:1.8068892265955607, acc:0.6905238095238095, epoch:4\n",
      "Loss:1.7871411216372535, acc:0.6973809523809524, epoch:5\n",
      "Loss:1.7761115570295425, acc:0.7028809523809524, epoch:6\n",
      "Loss:1.7690182934715635, acc:0.7063809523809523, epoch:7\n",
      "Loss:1.7639548227673485, acc:0.7088809523809524, epoch:8\n",
      "Loss:1.7600223141851878, acc:0.7103571428571429, epoch:9\n"
     ]
    }
   ],
   "source": [
    "X = mnist_train.drop('label',axis=1).values/255.0\n",
    "y = mnist_train['label'].values\n",
    "d_train = Mnist(X,y)\n",
    "d_train = DataLoader(d_train,batch_size=8)\n",
    "m = Model()\n",
    "o = opt.SGD(m.parameters(),lr=0.01)\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    Losses = []\n",
    "    Accuracies = []\n",
    "    for j,batch in enumerate(d_train):\n",
    "        x = batch['X'].float()\n",
    "        y = batch['y']\n",
    "        p = m(x)\n",
    "        acc = (p.argmax(axis=1)==y).float().mean().item()\n",
    "        Accuracies.append(acc)\n",
    "        loss = ce(p,y)\n",
    "        Losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        o.step()\n",
    "        o.zero_grad()\n",
    "    l = sum(Losses)/len(Losses)    \n",
    "    a = sum(Accuracies)/len(Accuracies)\n",
    "    print(f'Loss:{l}, acc:{a}, epoch:{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54c9cc-b040-44eb-9c51-3388b9302fa0",
   "metadata": {},
   "source": [
    "### Prediction Loop\n",
    "- Prediction data in a form that I can use my model on\n",
    "- Don't want to track the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7dcab7e9-be53-433d-86fb-3e59bfd9ff7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 784 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4b9d4b6-ed9f-41c0-9999-9db1b5f75b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist_test.values/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7de72e7-285f-48a9-8044-2d43a2a5cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_predict(Dataset):\n",
    "    def __init__(self,X):\n",
    "        self.X = X\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.X[idx]\n",
    "        return {'X':x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "837405ab-8637-44a9-bca4-48a7856e1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = Mnist_predict(X)\n",
    "predict_data = DataLoader(predict_data,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ec17d28-6cb7-4e32-be0e-60436e1c9a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/01sjg2sx6tl3y72r2klm24c80000gn/T/ipykernel_24070/2995878503.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for batch in predict_data:\n",
    "    x = batch['X'].float()\n",
    "    with torch.no_grad():\n",
    "        p=m(x)\n",
    "        predictions.append(p.argmax(axis=1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b51a67b-eca2-4b09-97cb-618967b20e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 9, 4, 2, 7, 0, 2, 0, 0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8bc0a3-be3f-4e4d-b3d1-751ee6ee5230",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks: Writting an architecture\n",
    "\n",
    "$n_{out} = \\frac{n_{in}+2p-k}{s}+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa908e7a-8c09-4e11-8a6e-0f57af4a06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6,kernel_size=5,stride=1,padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6,out_channels = 16,kernel_size=5,stride=1,padding=0)\n",
    "        self.linear1 = nn.Linear(4*4*16,120)### change this to handle mnist data\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(120,84)\n",
    "        self.linear3 = nn.Linear(84,10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        x = self.conv1(X)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(x) ## batch,5,5,16\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed0b9049-8376-4e09-9693-ff9abee57934",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()## use on mnist data (28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "42688263-6046-479f-9438-b0590555c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b3824174-355e-4129-a207-a0a1d896ef09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1012, 0.0986, 0.0915, 0.0997, 0.0959, 0.0867, 0.1065, 0.1090, 0.1061,\n",
       "         0.1049]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "272a6a40-85f5-4a89-9277-080c943ae148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0b30ad5-fc1e-4332-aa36-7c9405648dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return {'X':x.reshape((1,28,28)),'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7593556c-a3be-49fd-a902-88b872d8d20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:1.6320313571158567, acc:0.8343726199543031, epoch:0\n",
      "Loss:1.502194032447536, acc:0.9600390327494288, epoch:1\n",
      "Loss:1.4927641727138092, acc:0.96875, epoch:2\n",
      "Loss:1.4859093868904956, acc:0.9758187357197258, epoch:3\n",
      "Loss:1.483908484296225, acc:0.9775561690784463, epoch:4\n",
      "Loss:1.481959877627911, acc:0.9794126047220106, epoch:5\n",
      "Loss:1.4807682477692476, acc:0.980436024371668, epoch:6\n",
      "Loss:1.4795370581308032, acc:0.9815784463061691, epoch:7\n",
      "Loss:1.4780893658102694, acc:0.9830778750952018, epoch:8\n",
      "Loss:1.4783071876026161, acc:0.9828874714394517, epoch:9\n"
     ]
    }
   ],
   "source": [
    "X = mnist_train.drop('label',axis=1).values/255.0\n",
    "y = mnist_train['label'].values\n",
    "d_train = Mnist_CNN(X,y)\n",
    "d_train = DataLoader(d_train,batch_size=32)\n",
    "mod = CNN()\n",
    "ce = nn.CrossEntropyLoss()\n",
    "o = opt.Adam(mod.parameters(),lr=0.001)\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    Losses = []\n",
    "    Accuracies = []\n",
    "    for j,batch in enumerate(d_train):\n",
    "        x = batch['X'].float()\n",
    "        y = batch['y']\n",
    "        p = mod(x)\n",
    "        acc = (p.argmax(axis=1)==y).float().mean().item()\n",
    "        Accuracies.append(acc)\n",
    "        loss = ce(p,y)\n",
    "        Losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        o.step()\n",
    "        o.zero_grad()\n",
    "    l = sum(Losses)/len(Losses)    \n",
    "    a = sum(Accuracies)/len(Accuracies)\n",
    "    print(f'Loss:{l}, acc:{a}, epoch:{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea16f00-6977-4be8-a8d2-ac0ee943f7bc",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "- Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ea095c4-9365-4cf9-8636-e5e916d6b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14e7e0f7-a15e-4264-b0f8-e7ddef732087",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "25e9b09b-c93c-442b-b43e-c0938e535bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../codes/imgs/elephant.jpg\"\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "17e183cb-51b2-4a9c-a11a-999720fa837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f40595f6-e530-4e3c-9e0a-4d254056c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3d062ca8-fa93-4902-a3ec-ce8a1c0639bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "image_transforms=transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "                                transforms.Resize(size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a8fc662-d54e-4805-a7f6-59c767d32598",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1287616-c254-47a3-a553-5fe0a7c73b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 426])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "efdeac45-e40d-42d1-93fb-d455aaaddf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3835143e-989a-47b3-96c2-c7cea6b85f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([386])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1(img).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e8f6537c-b72d-4eff-82e6-c91fa9c84d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_labels = \"../data/vgg16_model_labels.csv\"\n",
    "lookup = pd.read_csv(path_labels,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e40fd359-90dd-4060-883c-63489511a5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386    African elephant, Loxodonta africana\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup[lookup[0]==386][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3894eca4-e735-4e57-9a48-20391e1fa844",
   "metadata": {},
   "source": [
    "### How to work with data (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "43461048-5db3-4452-9287-f88140f246dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/gunnvantsaini/Documents/Data/Work/ML Course/Module 5 Neural Networks/Data/waffle_pancakes/train\"\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "77e90a58-2fe3-4d8a-bc6b-4dfff9e19e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 150\n",
    "image_transforms=transforms.Compose([transforms.Resize((size,size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "train=datasets.ImageFolder(path,image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6acb198-6ae4-47fd-a76f-3f9e27b96893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batched = DataLoader(train,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2f193d0f-4685-476b-91a3-7376ea01d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pancakes', 'waffles']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4ae8b050-e022-4ff6-aa91-1cc339ee36be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pancakes': 0, 'waffles': 1}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd9c8453-9e45-451b-903b-f336499d0594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "248faf1a-e462-4ccd-9bf5-cce2f7ff8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in m1.parameters():\n",
    "    p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4d99e5bf-e704-4d03-8998-9286c1279116",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.classifier = nn.Sequential(nn.Linear(7*7*512,20),nn.ReLU(),nn.Linear(20,10),nn.ReLU(),nn.Linear(10,2),nn.Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "750132b6-88f6-478b-8068-19dff4be7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in m1.parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "71bf2d28-fe06-4d86-8749-00fa21939b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniforge3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.5064109573238774, acc:0.8210526319710831, epoch:0\n"
     ]
    }
   ],
   "source": [
    "ce = nn.CrossEntropyLoss()\n",
    "o = opt.SGD(m1.parameters(),lr=0.01)\n",
    "epochs = 1\n",
    "for i in range(epochs):\n",
    "    Losses = []\n",
    "    Accuracies = []\n",
    "    for j,batch in enumerate(train_batched):\n",
    "        x,y = batch\n",
    "        p = m1(x)\n",
    "        acc = (p.argmax(axis=1)==y).float().mean().item()\n",
    "        Accuracies.append(acc)\n",
    "        loss = ce(p,y)\n",
    "        Losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        o.step()\n",
    "        o.zero_grad()\n",
    "    l = sum(Losses)/len(Losses)    \n",
    "    a = sum(Accuracies)/len(Accuracies)\n",
    "    print(f'Loss:{l}, acc:{a}, epoch:{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22900c2-7a0b-4189-86fd-5b60e7565ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
